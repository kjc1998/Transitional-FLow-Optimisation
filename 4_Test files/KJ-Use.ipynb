{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matching_Points (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function Matching_Points(Input::Real,x::AbstractVector, y::AbstractVector)\n",
    "    Up = searchsortedfirst(x, Input)\n",
    "    if Input == x[Up]\n",
    "        Output = y[Up]\n",
    "    else\n",
    "        Low = Up - 1\n",
    "        Output = y[Low] + ((Input - x[Low])/(x[Up] - x[Low]))*(y[Up]-y[Low])\n",
    "    end\n",
    "    return Output\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matching_Points(3.5,[2,3,4,5,6,7],[4,6,8,10,12,14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file C:\\Users\\Kaijie\\.julia\\compiled\\v1.2\\ToySystems\\chsON.ji for ToySystems [53c88820-6eff-5a8c-9a74-badd815e7be1]\n",
      "└ @ Base loading.jl:1240\n",
      "┌ Warning: Package ToySystems does not have Flows in its dependencies:\n",
      "│ - If you have ToySystems checked out for development and have\n",
      "│   added Flows as a dependency but haven't updated your primary\n",
      "│   environment's manifest file, try `Pkg.resolve()`.\n",
      "│ - Otherwise you may need to report an issue with ToySystems\n",
      "└ Loading Flows into ToySystems from project dependency, future warnings for ToySystems are suppressed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "η2int (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Flows\n",
    "using ToySystems\n",
    "using ToySystems.NineModeSystemEq\n",
    "using Optim\n",
    "using PyPlot; pygui(true)\n",
    "include(\"9msctrl.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function test(x::AbstractVector)\n",
    "    return (1.0 - x[1])^2 + 100.0 * (x[2] - x[1]^2)^2\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Minimizer: [1.00e+00, 1.00e+00]\n",
       "    Minimum:   5.471433e-17\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     BFGS\n",
       "    Initial Point: [0.00e+00, 0.00e+00]\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 3.47e-07 ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = 3.47e-07 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = 6.59e-14 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 1.20e+03 ≰ 0.0e+00\n",
       "    |g(x)|                 = 2.33e-09 ≤ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   1  (vs limit Inf)\n",
       "    Iterations:    16\n",
       "    f(x) calls:    53\n",
       "    ∇f(x) calls:   53\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = optimize(test, zeros(2), BFGS())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mu\u001b[22m\u001b[0m\u001b[1ml\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "No documentation found.\n",
       "\n",
       "\\texttt{result} is of type \\texttt{Optim.MultivariateOptimizationResults\\{BFGS\\{LineSearches.InitialStatic\\{Float64\\},LineSearches.HagerZhang\\{Float64,Base.RefValue\\{Bool\\}\\},Nothing,Nothing,Flat\\},Float64,Array\\{Float64,1\\},Float64,Float64,Array\\{OptimizationState\\{Float64,BFGS\\{LineSearches.InitialStatic\\{Float64\\},LineSearches.HagerZhang\\{Float64,Base.RefValue\\{Bool\\}\\},Nothing,Nothing,Flat\\}\\},1\\},Bool\\}}.\n",
       "\n",
       "\\section{Summary}\n",
       "\\begin{verbatim}\n",
       "mutable struct Optim.MultivariateOptimizationResults{BFGS{LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}},Nothing,Nothing,Flat},Float64,Array{Float64,1},Float64,Float64,Array{OptimizationState{Float64,BFGS{LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}},Nothing,Nothing,Flat}},1},Bool} <: Optim.OptimizationResults\n",
       "\\end{verbatim}\n",
       "\\section{Fields}\n",
       "\\begin{verbatim}\n",
       "method              :: BFGS{LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}},Nothing,Nothing,Flat}\n",
       "initial_x           :: Array{Float64,1}\n",
       "minimizer           :: Array{Float64,1}\n",
       "minimum             :: Float64\n",
       "iterations          :: Int64\n",
       "iteration_converged :: Bool\n",
       "x_converged         :: Bool\n",
       "x_abstol            :: Float64\n",
       "x_reltol            :: Float64\n",
       "x_abschange         :: Float64\n",
       "x_relchange         :: Float64\n",
       "f_converged         :: Bool\n",
       "f_abstol            :: Float64\n",
       "f_reltol            :: Float64\n",
       "f_abschange         :: Float64\n",
       "f_relchange         :: Float64\n",
       "g_converged         :: Bool\n",
       "g_abstol            :: Float64\n",
       "g_residual          :: Float64\n",
       "f_increased         :: Bool\n",
       "trace               :: Array{OptimizationState{Float64,BFGS{LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}},Nothing,Nothing,Flat}},1}\n",
       "f_calls             :: Int64\n",
       "g_calls             :: Int64\n",
       "h_calls             :: Int64\n",
       "ls_success          :: Bool\n",
       "time_limit          :: Float64\n",
       "time_run            :: Float64\n",
       "\\end{verbatim}\n",
       "\\section{Supertype Hierarchy}\n",
       "\\begin{verbatim}\n",
       "Optim.MultivariateOptimizationResults{BFGS{LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}},Nothing,Nothing,Flat},Float64,Array{Float64,1},Float64,Float64,Array{OptimizationState{Float64,BFGS{LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}},Nothing,Nothing,Flat}},1},Bool} <: Optim.OptimizationResults <: Any\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "No documentation found.\n",
       "\n",
       "`result` is of type `Optim.MultivariateOptimizationResults{BFGS{LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}},Nothing,Nothing,Flat},Float64,Array{Float64,1},Float64,Float64,Array{OptimizationState{Float64,BFGS{LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}},Nothing,Nothing,Flat}},1},Bool}`.\n",
       "\n",
       "# Summary\n",
       "\n",
       "```\n",
       "mutable struct Optim.MultivariateOptimizationResults{BFGS{LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}},Nothing,Nothing,Flat},Float64,Array{Float64,1},Float64,Float64,Array{OptimizationState{Float64,BFGS{LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}},Nothing,Nothing,Flat}},1},Bool} <: Optim.OptimizationResults\n",
       "```\n",
       "\n",
       "# Fields\n",
       "\n",
       "```\n",
       "method              :: BFGS{LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}},Nothing,Nothing,Flat}\n",
       "initial_x           :: Array{Float64,1}\n",
       "minimizer           :: Array{Float64,1}\n",
       "minimum             :: Float64\n",
       "iterations          :: Int64\n",
       "iteration_converged :: Bool\n",
       "x_converged         :: Bool\n",
       "x_abstol            :: Float64\n",
       "x_reltol            :: Float64\n",
       "x_abschange         :: Float64\n",
       "x_relchange         :: Float64\n",
       "f_converged         :: Bool\n",
       "f_abstol            :: Float64\n",
       "f_reltol            :: Float64\n",
       "f_abschange         :: Float64\n",
       "f_relchange         :: Float64\n",
       "g_converged         :: Bool\n",
       "g_abstol            :: Float64\n",
       "g_residual          :: Float64\n",
       "f_increased         :: Bool\n",
       "trace               :: Array{OptimizationState{Float64,BFGS{LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}},Nothing,Nothing,Flat}},1}\n",
       "f_calls             :: Int64\n",
       "g_calls             :: Int64\n",
       "h_calls             :: Int64\n",
       "ls_success          :: Bool\n",
       "time_limit          :: Float64\n",
       "time_run            :: Float64\n",
       "```\n",
       "\n",
       "# Supertype Hierarchy\n",
       "\n",
       "```\n",
       "Optim.MultivariateOptimizationResults{BFGS{LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}},Nothing,Nothing,Flat},Float64,Array{Float64,1},Float64,Float64,Array{OptimizationState{Float64,BFGS{LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}},Nothing,Nothing,Flat}},1},Bool} <: Optim.OptimizationResults <: Any\n",
       "```\n"
      ],
      "text/plain": [
       "  No documentation found.\n",
       "\n",
       "  \u001b[36mresult\u001b[39m is of type\n",
       "  \u001b[36mOptim.MultivariateOptimizationResults{BFGS{LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}},Nothing,Nothing,Flat},Float64,Array{Float64,1},Float64,Float64,Array{OptimizationState{Float64,BFGS{LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}},Nothing,Nothing,Flat}},1},Bool}\u001b[39m.\n",
       "\n",
       "\u001b[1m  Summary\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  mutable struct Optim.MultivariateOptimizationResults{BFGS{LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}},Nothing,Nothing,Flat},Float64,Array{Float64,1},Float64,Float64,Array{OptimizationState{Float64,BFGS{LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}},Nothing,Nothing,Flat}},1},Bool} <: Optim.OptimizationResults\u001b[39m\n",
       "\n",
       "\u001b[1m  Fields\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  method              :: BFGS{LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}},Nothing,Nothing,Flat}\u001b[39m\n",
       "\u001b[36m  initial_x           :: Array{Float64,1}\u001b[39m\n",
       "\u001b[36m  minimizer           :: Array{Float64,1}\u001b[39m\n",
       "\u001b[36m  minimum             :: Float64\u001b[39m\n",
       "\u001b[36m  iterations          :: Int64\u001b[39m\n",
       "\u001b[36m  iteration_converged :: Bool\u001b[39m\n",
       "\u001b[36m  x_converged         :: Bool\u001b[39m\n",
       "\u001b[36m  x_abstol            :: Float64\u001b[39m\n",
       "\u001b[36m  x_reltol            :: Float64\u001b[39m\n",
       "\u001b[36m  x_abschange         :: Float64\u001b[39m\n",
       "\u001b[36m  x_relchange         :: Float64\u001b[39m\n",
       "\u001b[36m  f_converged         :: Bool\u001b[39m\n",
       "\u001b[36m  f_abstol            :: Float64\u001b[39m\n",
       "\u001b[36m  f_reltol            :: Float64\u001b[39m\n",
       "\u001b[36m  f_abschange         :: Float64\u001b[39m\n",
       "\u001b[36m  f_relchange         :: Float64\u001b[39m\n",
       "\u001b[36m  g_converged         :: Bool\u001b[39m\n",
       "\u001b[36m  g_abstol            :: Float64\u001b[39m\n",
       "\u001b[36m  g_residual          :: Float64\u001b[39m\n",
       "\u001b[36m  f_increased         :: Bool\u001b[39m\n",
       "\u001b[36m  trace               :: Array{OptimizationState{Float64,BFGS{LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}},Nothing,Nothing,Flat}},1}\u001b[39m\n",
       "\u001b[36m  f_calls             :: Int64\u001b[39m\n",
       "\u001b[36m  g_calls             :: Int64\u001b[39m\n",
       "\u001b[36m  h_calls             :: Int64\u001b[39m\n",
       "\u001b[36m  ls_success          :: Bool\u001b[39m\n",
       "\u001b[36m  time_limit          :: Float64\u001b[39m\n",
       "\u001b[36m  time_run            :: Float64\u001b[39m\n",
       "\n",
       "\u001b[1m  Supertype Hierarchy\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  Optim.MultivariateOptimizationResults{BFGS{LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}},Nothing,Nothing,Flat},Float64,Array{Float64,1},Float64,Float64,Array{OptimizationState{Float64,BFGS{LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}},Nothing,Nothing,Flat}},1},Bool} <: Optim.OptimizationResults <: Any\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " 0.9999999926033423\n",
       " 0.9999999852005353"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.minimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.x_abstol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mL\u001b[22m\u001b[0m\u001b[1mB\u001b[22m\u001b[0m\u001b[1mF\u001b[22m\u001b[0m\u001b[1mG\u001b[22m\u001b[0m\u001b[1mS\u001b[22m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\section{LBFGS}\n",
       "\\subsection{Constructor}\n",
       "\\begin{verbatim}\n",
       "LBFGS(; m::Integer = 10,\n",
       "alphaguess = LineSearches.InitialStatic(),\n",
       "linesearch = LineSearches.HagerZhang(),\n",
       "P=nothing,\n",
       "precondprep = (P, x) -> nothing,\n",
       "manifold = Flat(),\n",
       "scaleinvH0::Bool = true && (typeof(P) <: Nothing))\n",
       "\\end{verbatim}\n",
       "\\texttt{LBFGS} has two special keywords; the memory length \\texttt{m}, and the \\texttt{scaleinvH0} flag. The memory length determines how many previous Hessian approximations to store. When \\texttt{scaleinvH0 == true}, then the initial guess in the two-loop recursion to approximate the inverse Hessian is the scaled identity, as can be found in Nocedal and Wright (2nd edition) (sec. 7.2).\n",
       "\n",
       "In addition, LBFGS supports preconditioning via the \\texttt{P} and \\texttt{precondprep} keywords.\n",
       "\n",
       "\\subsection{Description}\n",
       "The \\texttt{LBFGS} method implements the limited-memory BFGS algorithm as described in Nocedal and Wright (sec. 7.2, 2006) and original paper by Liu \\& Nocedal (1989). It is a quasi-Newton method that updates an approximation to the Hessian using past approximations as well as the gradient.\n",
       "\n",
       "\\subsection{References}\n",
       "\\begin{itemize}\n",
       "\\item Wright, S. J. and J. Nocedal (2006), Numerical optimization, 2nd edition. Springer\n",
       "\n",
       "\n",
       "\\item Liu, D. C. and Nocedal, J. (1989). \"On the Limited Memory Method for Large Scale Optimization\". Mathematical Programming B. 45 (3): 503–528\n",
       "\n",
       "\\end{itemize}\n"
      ],
      "text/markdown": [
       "# LBFGS\n",
       "\n",
       "## Constructor\n",
       "\n",
       "```julia\n",
       "LBFGS(; m::Integer = 10,\n",
       "alphaguess = LineSearches.InitialStatic(),\n",
       "linesearch = LineSearches.HagerZhang(),\n",
       "P=nothing,\n",
       "precondprep = (P, x) -> nothing,\n",
       "manifold = Flat(),\n",
       "scaleinvH0::Bool = true && (typeof(P) <: Nothing))\n",
       "```\n",
       "\n",
       "`LBFGS` has two special keywords; the memory length `m`, and the `scaleinvH0` flag. The memory length determines how many previous Hessian approximations to store. When `scaleinvH0 == true`, then the initial guess in the two-loop recursion to approximate the inverse Hessian is the scaled identity, as can be found in Nocedal and Wright (2nd edition) (sec. 7.2).\n",
       "\n",
       "In addition, LBFGS supports preconditioning via the `P` and `precondprep` keywords.\n",
       "\n",
       "## Description\n",
       "\n",
       "The `LBFGS` method implements the limited-memory BFGS algorithm as described in Nocedal and Wright (sec. 7.2, 2006) and original paper by Liu & Nocedal (1989). It is a quasi-Newton method that updates an approximation to the Hessian using past approximations as well as the gradient.\n",
       "\n",
       "## References\n",
       "\n",
       "  * Wright, S. J. and J. Nocedal (2006), Numerical optimization, 2nd edition. Springer\n",
       "  * Liu, D. C. and Nocedal, J. (1989). \"On the Limited Memory Method for Large Scale Optimization\". Mathematical Programming B. 45 (3): 503–528\n"
      ],
      "text/plain": [
       "\u001b[1m  LBFGS\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[1m  Constructor\u001b[22m\n",
       "\u001b[1m  =============\u001b[22m\n",
       "\n",
       "\u001b[36m  LBFGS(; m::Integer = 10,\u001b[39m\n",
       "\u001b[36m  alphaguess = LineSearches.InitialStatic(),\u001b[39m\n",
       "\u001b[36m  linesearch = LineSearches.HagerZhang(),\u001b[39m\n",
       "\u001b[36m  P=nothing,\u001b[39m\n",
       "\u001b[36m  precondprep = (P, x) -> nothing,\u001b[39m\n",
       "\u001b[36m  manifold = Flat(),\u001b[39m\n",
       "\u001b[36m  scaleinvH0::Bool = true && (typeof(P) <: Nothing))\u001b[39m\n",
       "\n",
       "  \u001b[36mLBFGS\u001b[39m has two special keywords; the memory length \u001b[36mm\u001b[39m, and the \u001b[36mscaleinvH0\u001b[39m\n",
       "  flag. The memory length determines how many previous Hessian approximations\n",
       "  to store. When \u001b[36mscaleinvH0 == true\u001b[39m, then the initial guess in the two-loop\n",
       "  recursion to approximate the inverse Hessian is the scaled identity, as can\n",
       "  be found in Nocedal and Wright (2nd edition) (sec. 7.2).\n",
       "\n",
       "  In addition, LBFGS supports preconditioning via the \u001b[36mP\u001b[39m and \u001b[36mprecondprep\u001b[39m\n",
       "  keywords.\n",
       "\n",
       "\u001b[1m  Description\u001b[22m\n",
       "\u001b[1m  =============\u001b[22m\n",
       "\n",
       "  The \u001b[36mLBFGS\u001b[39m method implements the limited-memory BFGS algorithm as described\n",
       "  in Nocedal and Wright (sec. 7.2, 2006) and original paper by Liu & Nocedal\n",
       "  (1989). It is a quasi-Newton method that updates an approximation to the\n",
       "  Hessian using past approximations as well as the gradient.\n",
       "\n",
       "\u001b[1m  References\u001b[22m\n",
       "\u001b[1m  ============\u001b[22m\n",
       "\n",
       "    •    Wright, S. J. and J. Nocedal (2006), Numerical optimization, 2nd\n",
       "        edition. Springer\n",
       "\n",
       "    •    Liu, D. C. and Nocedal, J. (1989). \"On the Limited Memory Method\n",
       "        for Large Scale Optimization\". Mathematical Programming B. 45 (3):\n",
       "        503–528"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?LBFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Minimizer: [1.00e+00, 1.00e+00]\n",
       "    Minimum:   5.191703e-27\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     L-BFGS\n",
       "    Initial Point: [0.00e+00, 0.00e+00]\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 4.58e-11 ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = 4.58e-11 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = 4.41e-19 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 8.50e+07 ≰ 0.0e+00\n",
       "    |g(x)|                 = 1.44e-13 ≤ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   1  (vs limit Inf)\n",
       "    Iterations:    24\n",
       "    f(x) calls:    67\n",
       "    ∇f(x) calls:   67\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0 = [0.0, 0.0]\n",
    "\n",
    "f(x::AbstractVector) = (1.0 - x[1])^2 + 100.0 * (x[2] - x[1]^2)^2\n",
    "\n",
    "function g!(G::AbstractVector, x::AbstractVector)\n",
    "    G[1] = -2.0 * (1.0 - x[1]) - 400.0 * (x[2] - x[1]^2) * x[1]\n",
    "    G[2] = 200.0 * (x[2] - x[1]^2)\n",
    "end\n",
    "\n",
    "optimize(f, g!, x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "g! (generic function with 4 methods)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function g!(G::AbstractVector, x::AbstractVector)\n",
    "    G[1] = -2.0 * (1.0 - x[1]) - 400.0 * (x[2] - x[1]^2) * x[1]\n",
    "    G[2] = 200.0 * (x[2] - x[1]^2)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mg\u001b[22m\u001b[0m\u001b[1m!\u001b[22m mer\u001b[0m\u001b[1mg\u001b[22me\u001b[0m\u001b[1m!\u001b[22m \u001b[0m\u001b[1mg\u001b[22met\u001b[0m\u001b[1m!\u001b[22m di\u001b[0m\u001b[1mg\u001b[22mits\u001b[0m\u001b[1m!\u001b[22m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "No documentation found.\n",
       "\n",
       "\\texttt{g!} is a \\texttt{Function}.\n",
       "\n",
       "\\begin{verbatim}\n",
       "# 4 methods for generic function \"g!\":\n",
       "[1] g!(G::Array{Int64,1}, x::Array{Int64,1}) in Main at In[14]:2\n",
       "[2] g!(G::Array, x::Array) in Main at In[12]:2\n",
       "[3] g!(G::AbstractArray{T,1} where T, x::AbstractArray{T,1} where T) in Main at In[17]:2\n",
       "[4] g!(G, x) in Main at In[4]:6\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "No documentation found.\n",
       "\n",
       "`g!` is a `Function`.\n",
       "\n",
       "```\n",
       "# 4 methods for generic function \"g!\":\n",
       "[1] g!(G::Array{Int64,1}, x::Array{Int64,1}) in Main at In[14]:2\n",
       "[2] g!(G::Array, x::Array) in Main at In[12]:2\n",
       "[3] g!(G::AbstractArray{T,1} where T, x::AbstractArray{T,1} where T) in Main at In[17]:2\n",
       "[4] g!(G, x) in Main at In[4]:6\n",
       "```\n"
      ],
      "text/plain": [
       "  No documentation found.\n",
       "\n",
       "  \u001b[36mg!\u001b[39m is a \u001b[36mFunction\u001b[39m.\n",
       "\n",
       "\u001b[36m  # 4 methods for generic function \"g!\":\u001b[39m\n",
       "\u001b[36m  [1] g!(G::Array{Int64,1}, x::Array{Int64,1}) in Main at In[14]:2\u001b[39m\n",
       "\u001b[36m  [2] g!(G::Array, x::Array) in Main at In[12]:2\u001b[39m\n",
       "\u001b[36m  [3] g!(G::AbstractArray{T,1} where T, x::AbstractArray{T,1} where T) in Main at In[17]:2\u001b[39m\n",
       "\u001b[36m  [4] g!(G, x) in Main at In[4]:6\u001b[39m"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?g!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array{Int64,1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter     Function value   Gradient norm \n",
      "     0     1.000000e+00     2.000000e+00\n",
      " * time: 0.0\n",
      "     1     8.415971e-01     1.578600e+00\n",
      " * time: 0.1809999942779541\n",
      "     2     7.767204e-01     1.874904e+00\n",
      " * time: 0.19499993324279785\n",
      "     3     7.080698e-01     1.689587e+00\n",
      " * time: 0.2200000286102295\n",
      "     4     6.355493e-01     2.040685e+00\n",
      " * time: 0.2669999599456787\n",
      "     5     5.408975e-01     1.874498e+00\n",
      " * time: 0.3020000457763672\n",
      "     6     3.946973e-01     2.388404e+00\n",
      " * time: 0.31599998474121094\n",
      "     7     2.122648e-01     3.088179e+00\n",
      " * time: 0.372999906539917\n",
      "     8     1.724238e-01     2.845193e+00\n",
      " * time: 0.40799999237060547\n",
      "     9     1.308117e-01     1.573630e+00\n",
      " * time: 0.44300007820129395\n",
      "    10     1.159601e-01     9.001900e-01\n",
      " * time: 0.48000001907348633\n",
      "    11     1.031448e-01     3.164160e-01\n",
      " * time: 0.505000114440918\n",
      "    12     8.840496e-02     1.056332e+00\n",
      " * time: 0.5080001354217529\n",
      "    13     7.705036e-02     2.502819e+00\n",
      " * time: 0.5109999179840088\n",
      "    14     6.746256e-02     3.751973e+00\n",
      " * time: 0.5250000953674316\n",
      "    15     2.888655e-02     3.825459e+00\n",
      " * time: 0.5499999523162842\n",
      "    16     1.541276e-02     2.422629e-01\n",
      " * time: 0.5989999771118164\n",
      "    17     6.727998e-03     5.703931e-01\n",
      " * time: 0.6210000514984131\n",
      "    18     3.603446e-03     1.264546e+00\n",
      " * time: 0.6470000743865967\n",
      "    19     1.320727e-04     4.150293e-01\n",
      " * time: 0.6510000228881836\n",
      "    20     3.412485e-05     2.018405e-02\n",
      " * time: 0.6670000553131104\n",
      "    21     3.454513e-08     7.409729e-03\n",
      " * time: 0.6809999942779541\n",
      "    22     1.177789e-10     1.617521e-05\n",
      " * time: 0.7049999237060547\n",
      "    23     4.414066e-19     2.659272e-08\n",
      " * time: 0.7200000286102295\n",
      "    24     5.191703e-27     1.441069e-13\n",
      " * time: 0.7799999713897705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Minimizer: [1.00e+00, 1.00e+00, 0.00e+00]\n",
       "    Minimum:   5.191703e-27\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     L-BFGS\n",
       "    Initial Point: [0.00e+00, 0.00e+00, 0.00e+00]\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 4.58e-11 ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = 4.58e-11 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = 4.41e-19 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 8.50e+07 ≰ 0.0e+00\n",
       "    |g(x)|                 = 1.44e-13 ≤ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   1  (vs limit Inf)\n",
       "    Iterations:    24\n",
       "    f(x) calls:    67\n",
       "    ∇f(x) calls:   67\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0 = [0.0, 0.0, 0.0]\n",
    "\n",
    "f(x::AbstractVector) = (1.0 - x[1])^2 + 100.0 * (x[2] - x[1]^2)^2 + x[3]^2\n",
    "\n",
    "function g!(G::AbstractVector, x::AbstractVector)\n",
    "    G[1] = -2.0 * (1.0 - x[1]) - 400.0 * (x[2] - x[1]^2) * x[1]\n",
    "    G[2] = 200.0 * (x[2] - x[1]^2)\n",
    "    G[3] = 2*x[3]\n",
    "end\n",
    "\n",
    "optimize(f, g!, x0, LBFGS(),Optim.Options(show_trace=true, iterations = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500-element Array{Float64,1}:\n",
       " NaN                  \n",
       " NaN                  \n",
       " NaN                  \n",
       "   0.3207550581218382 \n",
       "   0.37028401681929096\n",
       "   0.47250867065805036\n",
       "   0.5996765670336731 \n",
       "   0.7402048112678248 \n",
       "   0.8825330413779299 \n",
       "   1.017633219528765  \n",
       "   1.1404220256990218 \n",
       "   1.2491419606603604 \n",
       "   1.3440887427735322 \n",
       "   ⋮                  \n",
       "   3.561642166815291  \n",
       "   3.562046727522338  \n",
       "   3.5624497291697836 \n",
       "   3.56285118075293   \n",
       "   3.5632510911980217 \n",
       "   3.5636494693629004 \n",
       "   3.5640463240376614 \n",
       "   3.564441663945299  \n",
       "   3.5648354977423433 \n",
       "   3.565227834019499  \n",
       "   3.565618681302258  \n",
       "   3.566008048051529  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Re = 1:2:1000\n",
    "u0 = rand(9)\n",
    "dadt = zeros(9)\n",
    "q    = zeros(9)\n",
    "dqdt = zeros(9)\n",
    "T    = 9.8\n",
    "timestep = 0.7\n",
    "ts = 0:timestep:T\n",
    "store = RAMStorage(zeros(9))\n",
    "B = [0,0,0,0,1,0,0,0,0]\n",
    "\n",
    "objfun(u::AbstractVector) = (u[1] - 1)^2 + sum(u[i]^2 for i = 2:9)\n",
    "function objfun(t, u, dudt, I, dIdt)\n",
    "    return dIdt[1] = (u[1] - 1)^2 + sum(u[i]^2 for i = 2:9)\n",
    "end\n",
    "function objfun(xq::Coupled)\n",
    "    return objfun(xq[1])\n",
    "end\n",
    "\n",
    "function Objective_fun_CTRL(η::AbstractVector)\n",
    "    Varyingarray = zeros(length(Re))\n",
    "    for i in 1:length(Re)\n",
    "        f = NineModeSystemCTRL(Re[i], ts, η)\n",
    "        ϕ = flow(couple(f,objfun),RK4(couple(zeros(9),zeros(1))), TimeStepConstant(timestep))\n",
    "        I0 = Float64[0.0]\n",
    "        u0_local = copy(u0)\n",
    "        ϕ(couple(u0_local, I0), extrema(ts))\n",
    "        Varyingarray[i] = I0[1]/T\n",
    "    end\n",
    "    plot(Re, Varyingarray)\n",
    "    xlabel(L\"Re\")\n",
    "    ylabel(L\"objfun(t)\")\n",
    "    return Varyingarray\n",
    "end\n",
    "\n",
    "y_array = Objective_fun_CTRL(zeros(length(ts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Array{Int64,1},1}:\n",
       " [1, 2, 3]\n",
       " [4, 5, 6]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = [[1,2,3],[4,5,6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×4 Array{Float64,2}:\n",
       " 0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CCP = zeros(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Multiple_timestep (generic function with 1 method)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function minus_energy_grad(t, a, dadt, v, dvdt)\n",
    "    dvdt[1] += -2*(a[1] - 1)\n",
    "    for i = 2:9\n",
    "        dvdt[i] += -2*a[i]\n",
    "    end\n",
    "    return dvdt\n",
    "end\n",
    "\n",
    "\n",
    "objfun(u::AbstractVector) = (u[1] - 1)^2 + sum(u[i]^2 for i = 2:9)\n",
    "function objfun(t, u, dudt, I, dIdt)\n",
    "    return dIdt[1] = (u[1] - 1)^2 + sum(u[i]^2 for i = 2:9)\n",
    "end\n",
    "function objfun(xq::Coupled)\n",
    "    return objfun(xq[1])\n",
    "end\n",
    "\n",
    "function Multiple_timestep(δts::AbstractVector, Re::Real)\n",
    "    array = zeros(length(δts))\n",
    "    for i in 1:length(δts)\n",
    "        store = RAMStorage(zeros(9))\n",
    "        timestep1 = δts[i]\n",
    "        if T != round(T/timestep1)*δts[i]\n",
    "            T1 = (round(T/timestep1)+2)*δts[i]\n",
    "        else \n",
    "            T1 = round(T/timestep1)*δts[i]\n",
    "        end\n",
    "        ts1 = 0:timestep1:T1\n",
    "        function Objective_fun_CTRL(η::AbstractVector)\n",
    "            f = NineModeSystemCTRL(Re, ts1, η)\n",
    "            ϕ = flow(couple(f,objfun),RK4(couple(zeros(9),zeros(1))), TimeStepConstant(timestep1))\n",
    "            I0 = Float64[0.0]\n",
    "            u0_local = copy(u0)\n",
    "            ϕ(couple(u0_local, I0), extrema(ts1))\n",
    "            return I0[1]/T1\n",
    "        end\n",
    "\n",
    "        function Objective_fun_Gradient!(G::AbstractVector,η::AbstractVector)\n",
    "            f = NineModeSystemCTRL(Re, ts1, η)\n",
    "            ϕ = flow(f,RK4(zeros(9)), TimeStepConstant(timestep1))\n",
    "            u0_local = copy(u0)\n",
    "            ϕ(u0_local, (0, T1), reset!(store))\n",
    "\n",
    "            h = NineModeSystemLin(Re, true, minus_energy_grad)\n",
    "            ψ_adj = flow(h, RK4(zeros(9), ContinuousMode(true)), TimeStepFromStorage(timestep1))\n",
    "            mon = Monitor(zeros(9), q -> -B[5]*q[5])\n",
    "            ψ_adj(zeros(9), store, (T1, 0), reset!(mon))\n",
    "            G .= samples(mon)[end:-1:1]\n",
    "        end\n",
    "\n",
    "        output = optimize(Objective_fun_CTRL, Objective_fun_Gradient!, zeros(length(ts1)),LBFGS(),Optim.Options(f_tol = 1e-6,\n",
    "                                     store_trace = true,\n",
    "                                     show_trace = false))\n",
    "        array[i] = output.minimum\n",
    "    end\n",
    "    return array\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "ArgumentError: time 10.8 is out of range timespan(store)",
     "output_type": "error",
     "traceback": [
      "ArgumentError: time 10.8 is out of range timespan(store)",
      "",
      "Stacktrace:",
      " [1] (::RAMStorage{Float64,Array{Float64,1},3,Array{Float64,1},Array{Array{Float64,1},1}})(::Array{Float64,1}, ::Float64, ::Val{0}) at C:\\Users\\Kaijie\\.julia\\packages\\Flows\\brO3V\\src\\storage.jl:267",
      " [2] RAMStorage at C:\\Users\\Kaijie\\.julia\\packages\\Flows\\brO3V\\src\\storage.jl:259 [inlined]",
      " [3] step!(::RK4{Array{Float64,1},ContinuousMode{true},NTuple{6,Array{Float64,1}}}, ::Flows.System{1,CallDependency{1,((1,),)}(),NineModeSystemLin{true,1,Tuple{typeof(minus_energy_grad)}},Nothing}, ::Float64, ::Float64, ::Array{Float64,1}, ::RAMStorage{Float64,Array{Float64,1},3,Array{Float64,1},Array{Array{Float64,1},1}}) at C:\\Users\\Kaijie\\.julia\\packages\\Flows\\brO3V\\src\\steps\\rk4.jl:64",
      " [4] _propagate!(::RK4{Array{Float64,1},ContinuousMode{true},NTuple{6,Array{Float64,1}}}, ::TimeStepFromStorage, ::Flows.System{1,CallDependency{1,((1,),)}(),NineModeSystemLin{true,1,Tuple{typeof(minus_energy_grad)}},Nothing}, ::Tuple{Float64,Float64}, ::Array{Float64,1}, ::RAMStorage{Float64,Array{Float64,1},3,Array{Float64,1},Array{Array{Float64,1},1}}, ::Monitor{Float64,Float64,RAMStorage{Float64,Float64,3,Array{Float64,1},Array{Float64,1}},getfield(Main, Symbol(\"##95#98\"))}) at C:\\Users\\Kaijie\\.julia\\packages\\Flows\\brO3V\\src\\integrator.jl:365",
      " [5] (::Flows.Flow{TimeStepFromStorage,RK4{Array{Float64,1},ContinuousMode{true},NTuple{6,Array{Float64,1}}},Flows.System{1,CallDependency{1,((1,),)}(),NineModeSystemLin{true,1,Tuple{typeof(minus_energy_grad)}},Nothing}})(::Array{Float64,1}, ::RAMStorage{Float64,Array{Float64,1},3,Array{Float64,1},Array{Array{Float64,1},1}}, ::Tuple{Float64,Int64}, ::Monitor{Float64,Float64,RAMStorage{Float64,Float64,3,Array{Float64,1},Array{Float64,1}},getfield(Main, Symbol(\"##95#98\"))}) at C:\\Users\\Kaijie\\.julia\\packages\\Flows\\brO3V\\src\\integrator.jl:152",
      " [6] (::getfield(Main, Symbol(\"#Objective_fun_Gradient!#97\")){Int64,RAMStorage{Float64,Array{Float64,1},3,Array{Float64,1},Array{Array{Float64,1},1}},Float64,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}})(::Array{Float64,1}, ::Array{Float64,1}) at .\\In[94]:47",
      " [7] (::getfield(NLSolversBase, Symbol(\"#fg!#8\")){getfield(Main, Symbol(\"#Objective_fun_CTRL#96\")){Int64,Float64,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}},getfield(Main, Symbol(\"#Objective_fun_Gradient!#97\")){Int64,RAMStorage{Float64,Array{Float64,1},3,Array{Float64,1},Array{Array{Float64,1},1}},Float64,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}})(::Array{Float64,1}, ::Array{Float64,1}) at C:\\Users\\Kaijie\\.julia\\packages\\NLSolversBase\\NsXIC\\src\\objective_types\\abstract.jl:13",
      " [8] value_gradient!!(::OnceDifferentiable{Float64,Array{Float64,1},Array{Float64,1}}, ::Array{Float64,1}) at C:\\Users\\Kaijie\\.julia\\packages\\NLSolversBase\\NsXIC\\src\\interface.jl:82",
      " [9] initial_state(::LBFGS{Nothing,LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}},getfield(Optim, Symbol(\"##19#21\"))}, ::Optim.Options{Float64,Nothing}, ::OnceDifferentiable{Float64,Array{Float64,1},Array{Float64,1}}, ::Array{Float64,1}) at C:\\Users\\Kaijie\\.julia\\packages\\Optim\\EhyUl\\src\\multivariate\\solvers\\first_order\\l_bfgs.jl:158",
      " [10] optimize(::OnceDifferentiable{Float64,Array{Float64,1},Array{Float64,1}}, ::Array{Float64,1}, ::LBFGS{Nothing,LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}},getfield(Optim, Symbol(\"##19#21\"))}, ::Optim.Options{Float64,Nothing}) at C:\\Users\\Kaijie\\.julia\\packages\\Optim\\EhyUl\\src\\multivariate\\optimize\\optimize.jl:33",
      " [11] #optimize#94(::Bool, ::Symbol, ::typeof(optimize), ::Function, ::Function, ::Array{Float64,1}, ::LBFGS{Nothing,LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}},getfield(Optim, Symbol(\"##19#21\"))}, ::Optim.Options{Float64,Nothing}) at C:\\Users\\Kaijie\\.julia\\packages\\Optim\\EhyUl\\src\\multivariate\\optimize\\interface.jl:123",
      " [12] optimize(::Function, ::Function, ::Array{Float64,1}, ::LBFGS{Nothing,LineSearches.InitialStatic{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}},getfield(Optim, Symbol(\"##19#21\"))}, ::Optim.Options{Float64,Nothing}) at C:\\Users\\Kaijie\\.julia\\packages\\Optim\\EhyUl\\src\\multivariate\\optimize\\interface.jl:121",
      " [13] Multiple_timestep(::StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}, ::Int64) at .\\In[94]:51",
      " [14] top-level scope at .\\In[98]:5"
     ]
    }
   ],
   "source": [
    "T = 10\n",
    "δts = 0.1:0.05:1\n",
    "Re = 100:100:1000\n",
    "for i in 1:length(Re)\n",
    "    y_array = Multiple_timestep(δts, Re[i])\n",
    "    plot(δts, y_array)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Int64,1}:\n",
       " 1\n",
       " 2\n",
       " 3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"9msctrl.jl\")\n",
    "η2int([1,2,3],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9-element Array{Float64,1}:\n",
       " 0.5777942839460433 \n",
       " 0.05652667872798367\n",
       " 0.46545177915665037\n",
       " 0.7586119154065878 \n",
       " 0.7037002662671497 \n",
       " 0.843368007523488  \n",
       " 0.5292028507165507 \n",
       " 0.9233694257249574 \n",
       " 0.8480334055459204 "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"Continuous.jl\")\n",
    "u0 = rand(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4.0318814003441625, 4.981648279475525, 5.8996848302398845, 6.079039972490243, 5.390505437002315, 4.625183347431454, 4.5735358858226975, 5.054645594903119, 5.314362056401888, 4.985114744405481  …  0.8588072062528576, 0.8415670482250841, 0.8243722476405707, 0.8076579683539369, 0.7918851967407928, 0.7775243087602366, 0.7650365208741929, 0.7548541786625815, 0.7473611242242719, 0.7428745327905655], [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5  …  995.5, 996.0, 996.5, 997.0, 997.5, 998.0, 998.5, 999.0, 999.5, 1000.0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,Y = Objective_con_WCTRL(3000,10,copy(u0),1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
